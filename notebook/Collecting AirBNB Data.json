{
	"name": "Collecting AirBNB Data",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "RealEstate",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "5bfd14d7-b199-4ce5-b180-c70b0b02f6d7"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/53a5f707-d87c-4719-a352-95e693ea64db/resourceGroups/resource-group-realestate-project/providers/Microsoft.Synapse/workspaces/synapserealestate/bigDataPools/RealEstate",
				"name": "RealEstate",
				"type": "Spark",
				"endpoint": "https://synapserealestate.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/RealEstate",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Collecting AirBNB Data\n",
					"The purpose of this code to collect airBNB data from API and store them in Azure Data Lake"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "python",
						"language_group": "synapse_pyspark"
					}
				},
				"source": [
					"import requests\n",
					"import pandas as pd\n",
					"import json\n",
					"import time\n",
					"import datetime\n",
					"import os"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "python",
						"language_group": "synapse_pyspark"
					},
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_data(Address : str,Bath : str, Bed : str):\n",
					"    url = \"https://airdna1.p.rapidapi.com/rentalizer\"\n",
					"    \n",
					"    if len(Bed)>0:\n",
					"        querystring = {\"address\":Address,\"bedrooms\":Bed,\"bathrooms\":Bath}\n",
					"    else:\n",
					"        querystring = {\"address\":Address}\n",
					"\n",
					"    headers = {\n",
					"\t    \"x-rapidapi-key\": \"1bd9f55d72msh06a4a0fa1818ebep126179jsnf1ca25048267\",\n",
					"\t    \"x-rapidapi-host\": \"airdna1.p.rapidapi.com\"\n",
					"    }\n",
					"    response = requests.get(url, headers=headers, params=querystring)\n",
					"    return response.json()"
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "python",
						"language_group": "synapse_pyspark"
					},
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"from notebookutils import mssparkutils \n",
					"\n",
					"mssparkutils.fs.mount( \n",
					"    \"abfss://silver@dlakerealestate.dfs.core.windows.net\", \n",
					"    \"/silver\", \n",
					"    {\"linkedService\": \"AzureDataLakeStorage1\"} \n",
					") \n",
					"pathsilver = mssparkutils.fs.getMountPath(\"/silver\")\n",
					"print(pathsilver)"
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"source": [
					"mssparkutils.fs.mount(\n",
					"    \"abfss://bronze@dlakerealestate.dfs.core.windows.net\", \n",
					"    \"/bronze/AirBNBData/\", \n",
					"    {\"linkedService\": \"AzureDataLakeStorage1\"} \n",
					") \n",
					"pathbronze = mssparkutils.fs.getMountPath(\"/bronze/AirBNBData\")\n",
					"print(pathbronze)"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"source": [
					"directory_path=pathbronze+\"/AirBNBData\"\n",
					"files = os.listdir(directory_path)\n",
					"for file in files:\n",
					"    file_path = os.path.join(directory_path, file)\n",
					"    # print(file_path)\n",
					"    if os.path.isfile(file_path):\n",
					"         os.remove(file_path)"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"dfpropertyonmarket = pd.read_parquet(pathsilver+'/PropertyOnMarket/', engine='pyarrow')"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "python",
						"language_group": "synapse_pyspark"
					},
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"counter =0\n",
					"for index,row in dfpropertyonmarket.iterrows():\n",
					"    counter=counter+1\n",
					"    if(counter>=0):\n",
					"        completeaddress = row['Address']+\", \"+row[\"City\"]+\", \"+row[\"State\"]+\" \"+row[\"ZipCode\"]\n",
					"        data = get_data(str(completeaddress),str(row[\"Bathrooms\"]), str(row[\"Bedrooms\"]))\n",
					"        j=json.dumps(data) \n",
					"        with open(pathbronze+\"/AirBNBData/airbnb-data-\"+ str(row['ZPID'])+ \".json\",\"w\") as f:\n",
					"            f.write(j)\n",
					"            f.close()\n",
					"        # delay the request to limit 1 per second\n",
					"        if (counter%1)==0:\n",
					"            print(counter, \"delay \"+str(datetime.datetime.now()))\n",
					"            time.sleep(1)"
				],
				"execution_count": 52
			}
		]
	}
}
